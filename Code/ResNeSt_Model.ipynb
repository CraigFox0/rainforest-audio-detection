{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83f7e37",
   "metadata": {},
   "source": [
    "### Imports and Definition of Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9302d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchaudio in /home/tuj57093/.local/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: torchtext in /opt/conda/lib/python3.8/site-packages/torchtext-0.12.0a0-py3.8-linux-x86_64.egg (0.12.0a0)\n",
      "Requirement already satisfied: torch==1.11.0 in /home/tuj57093/.local/lib/python3.8/site-packages (from torchaudio) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /home/tuj57093/.local/lib/python3.8/site-packages (from torch==1.11.0->torchaudio) (4.1.1)\n",
      "Requirement already satisfied: tqdm in /home/tuj57093/.local/lib/python3.8/site-packages (from torchtext) (4.63.0)\n",
      "Requirement already satisfied: requests in /home/tuj57093/.local/lib/python3.8/site-packages (from torchtext) (2.27.1)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.12.0-cp38-cp38-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 13.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/tuj57093/.local/lib/python3.8/site-packages (from torchtext) (1.22.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tuj57093/.local/lib/python3.8/site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tuj57093/.local/lib/python3.8/site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tuj57093/.local/lib/python3.8/site-packages (from requests->torchtext) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/tuj57093/.local/lib/python3.8/site-packages (from requests->torchtext) (2.0.12)\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8495c89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/__init__.py:231\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m)\n\u001b[1;32m    232\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# issue 38137 and python issue 43367. Submodules of a C extension are\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# non-standard, and attributes of those submodules cannot be pickled since\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# pickle expect to be able to import them as \"from _C.sub import attr\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# which fails with \"_C is not a package\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(_C):\n",
      "\u001b[0;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torchvision import transform\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from resnest.torch import resnest50\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skimage.transform import resize\n",
    "import csv\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import csv\n",
    "import torch.utils.data as td\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "\n",
    "rng_seed = 1234\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_species = 24\n",
    "batch_size = 32\n",
    "\n",
    "fft = 2048\n",
    "hop = 512 \n",
    "# According to research, standard sampling bitrate is 48khz. Seen in discussion of kaggle competition as well. \n",
    "sr = 48000\n",
    "length = 10*sr\n",
    "\n",
    "data_path = '../Data/'\n",
    "\n",
    "# should change this according to nvidia-smi output e.g. \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "device = torch.device('cuda')\n",
    "\n",
    "tp = pd.read_csv(data_path + 'train_tp.csv')\n",
    "fp = pd.read_csv(data_path + 'train_fp.csv')\n",
    "fp['species_id'] = fp['species_id'].apply(lambda x : -x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1db41",
   "metadata": {},
   "source": [
    "### Creating Melspectrograms specifically for ResNeSt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24d7a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_spectograms(df, df2):\n",
    "    \n",
    "    mel_spectrogram_transform = MelSpectrogram(power=2.0, n_fft)\n",
    "    \n",
    "    df['spec'] = np.nan\n",
    "    df['spec'] = df['spec'].astype(object)\n",
    "    \n",
    "    df2['spec'] = np.nan\n",
    "    df2['spec'] = df2['spec'].astype(object)\n",
    "    \n",
    "    for idx,row in df.iterrows():\n",
    "\n",
    "        wav, sr = librosa.load(data_path + 'train/' + row['recording_id'] + '.flac', sr=None)\n",
    "        \n",
    "        # Slicing and centering spectograms \n",
    "        m = (int)((row['t_min'] + row['t_max'])*sr/2)\n",
    "    \n",
    "        l = (int)(m-(length/2))\n",
    "        r = (int)(m+(length/2))\n",
    "    \n",
    "        #Assumes audio files are at least as long as length\n",
    "        if l < 0:\n",
    "            r += l\n",
    "            l = 0\n",
    "        elif r > len(wav):\n",
    "            l -= r-len(wav)\n",
    "            r = len(wav)\n",
    "        \n",
    "        melspec = librosa.power_to_db(librosa.feature.melspectrogram(y=wav[int(l):int(r)], sr=sr))\n",
    "        \n",
    "        df.at[idx, 'spec'] = melspec\n",
    "        \n",
    "        \n",
    "    for idx,row in df2.iterrows():\n",
    "        wav, sr = librosa.load(data_path + 'train/' + row['recording_id'] + '.flac', sr=None)\n",
    "    \n",
    "       # Slicing and centering spectograms \n",
    "        m = (int)((row['t_min'] + row['t_max'])*sr/2)\n",
    "    \n",
    "        l = (int)(m-(length/2))\n",
    "        r = (int)(m+(length/2))\n",
    "    \n",
    "        #Assumes audio files are at least as long as length\n",
    "        if l < 0:\n",
    "            r += l\n",
    "            l = 0\n",
    "        elif r > len(wav):\n",
    "            l -= r-len(wav)\n",
    "            r = len(wav)\n",
    "        \n",
    "        melspec = librosa.power_to_db(librosa.feature.melspectrogram(y=wav[int(l):int(r)], sr=sr))\n",
    "        df2.at[idx, 'spec'] = mspec\n",
    "        \n",
    "    return pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57e8a022",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mspec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25457/3708461966.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mel_spectograms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_25457/2446661371.py\u001b[0m in \u001b[0;36mcreate_mel_spectograms\u001b[0;34m(df, df2)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmelspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'spec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mspec' is not defined"
     ]
    }
   ],
   "source": [
    "df = create_mel_spectograms(tp, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400825be",
   "metadata": {},
   "source": [
    "### Loading in Preproccessed Mel Spectrograms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772e99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to2DArray(x): \n",
    "    # casts object representation of specs stored in csv to a 2D numpy array \n",
    "    x=x.replace(\"[\", '')\n",
    "    x=x.replace(\"]\", '')\n",
    "    x=x.replace(\"...\", '')\n",
    "    x=x.replace(\"\\n\", '')\n",
    "    y=np.array(x.split(\" \"))\n",
    "    y = y[y != \"\"]\n",
    "    y = np.asfarray(y, 'float64')\n",
    "    y = np.reshape(y,(1, y.size))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bb824ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>[[0.01252426, 0.0023889802, 0.00061887037, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>[[1.1748381, 0.41643876, 1.1397215, 1.662797, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>[[0.02010685, 0.027764402, 0.022443173, 0.0535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>[[0.0031949885, 0.0043321564, 0.0011921478, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>[[0.018652013, 0.02159359, 0.06152439, 0.31434...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recording_id  species_id  songtype_id    t_min     f_min    t_max     f_max  \\\n",
       "0    003bec244          14            1  44.5440  2531.250  45.1307   5531.25   \n",
       "1    006ab765f          23            1  39.9615  7235.160  46.0452  11283.40   \n",
       "2    007f87ba2          12            1  39.1360   562.500  42.2720   3281.25   \n",
       "3    0099c367b          17            4  51.4206  1464.260  55.1996   4565.04   \n",
       "4    009b760e6          10            1  50.0854   947.461  52.5293  10852.70   \n",
       "\n",
       "                                                spec  \n",
       "0  [[0.01252426, 0.0023889802, 0.00061887037, 0.0...  \n",
       "1  [[1.1748381, 0.41643876, 1.1397215, 1.662797, ...  \n",
       "2  [[0.02010685, 0.027764402, 0.022443173, 0.0535...  \n",
       "3  [[0.0031949885, 0.0043321564, 0.0011921478, 0....  \n",
       "4  [[0.018652013, 0.02159359, 0.06152439, 0.31434...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['spec'] = df['spec'].apply(lambda x: to2DArray(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79f40a",
   "metadata": {},
   "source": [
    "### Dataset Definition and Additional Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5c2f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RainforestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # additional preprocessing required for ResNeST, normalization outlined in paper\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(320),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "                \n",
    "        labels = df['species_id']\n",
    "        for label in labels:\n",
    "            label_arr = np.full(24, .043478)\n",
    "            if label < 0:\n",
    "                label_arr[label] = 0\n",
    "            else:\n",
    "                label_arr[label] = 1\n",
    "            self.labels.append(label_arr)\n",
    "             \n",
    "        mspecs = df['spec']\n",
    "        \n",
    "        for i in range(len(mspecs)):\n",
    "            fig = plt.Figure()\n",
    "            canvas = FigureCanvas(fig)\n",
    "            current_mspec = librosa.display.specshow(mpecs[i])\n",
    "            current_mspec = self.preprocess(current_mspec)\n",
    "            self.data.append(current_mspec)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx], self.labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c8084a",
   "metadata": {},
   "source": [
    "### Model Definition and Loading to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe9d89b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model class definition \n",
    "model = resnest50(pretrained=False)\n",
    "\n",
    "# ResNeST pretrained model should be uploaded to this path with the notebook\n",
    "model.load_state_dict(torch.load(data_path + 'resnest50-528c19ca.pth'))\n",
    "model.eval()\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "# load model into GPU\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4)\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "loss_function.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d779a11",
   "metadata": {},
   "source": [
    "### Definition of Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc89ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_loader, val_loader, model, optimizer, scheduler, loss_function, e_poch):\n",
    "    best_correct = 0\n",
    "\n",
    "    for e in range(0, e_poch):\n",
    "        train_loss = []\n",
    "        \n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output = output.cuda()\n",
    "            \n",
    "            loss = loss_function(output, target)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            lr = g['lr']\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Training Loss: \", str(sum(train_loss) / len(train_loss)))\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_corr = []\n",
    "\n",
    "            model.eval()\n",
    "            for batch, (data, target) in enumerate(val_loader):\n",
    "                data = data.float()\n",
    "                if torch.cuda.is_available():\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "        \n",
    "                \n",
    "                output = model(data)\n",
    "                loss = loss_function(output, target)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                vals, answers = torch.max(output, 1)\n",
    "                vals, targets = torch.max(target, 1)\n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "                val_corr.append(corrects)\n",
    "\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Validation Loss: \", str(sum(val_loss) / len(val_loss)))\n",
    "\n",
    "\n",
    "        if sum(val_corr) > best_correct:\n",
    "            print('Saving new best model at epoch ' + str(e) + ' (' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()) + ')')\n",
    "            # torch.save(model, 'best_model_resnest.pth')\n",
    "            best_correct = sum(val_corr)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    del model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ce473",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e18c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = None\n",
    "val_df = None\n",
    "\n",
    "X = df.drop('species_id', axis=1)\n",
    "y = df['species_id']\n",
    "\n",
    "strat = StratifiedKFold(n_splits=2, shuffle=True, random_state=rng_seed)\n",
    "train_dfs=[]\n",
    "val_dfs=[]\n",
    "\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(strat.split(X,y)):\n",
    "    train_df = df.iloc[train_index]\n",
    "    val_df = df.iloc[val_index]\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    train_dfs.append(train_df)\n",
    "    val_dfs.append(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19d0d8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27ade88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 401)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 89)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 922)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 898)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 859)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 408)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 172)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 531)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 574)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 270)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 272)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 324)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 290)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 592)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 782)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 781)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 817)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 449)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 769)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 795)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 619)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 104)\n",
      "(128, 938)\n",
      "(128, 569)\n",
      "(128, 938)\n",
      "(128, 348)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 260)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 932)\n",
      "(128, 938)\n",
      "(128, 394)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 438)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 420)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 638)\n",
      "(128, 740)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 165)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 191)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 870)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 755)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 931)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 647)\n",
      "(128, 650)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 670)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 418)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 436)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 586)\n",
      "(128, 938)\n",
      "(128, 180)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 245)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 688)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 480)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 700)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 854)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 860)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 892)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 796)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 352)\n",
      "(128, 406)\n",
      "(128, 938)\n",
      "(128, 496)\n",
      "(128, 182)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 182)\n",
      "(128, 938)\n",
      "(128, 249)\n",
      "(128, 938)\n",
      "(128, 467)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 874)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n",
      "(128, 938)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25457/2868984618.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0me_poch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRainforestDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRainforestDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25457/2076602413.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mcurrent_mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mcurrent_mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_long\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_short\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1978\u001b[0m                 )\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e_poch = 20\n",
    "train_dataset = RainforestDataset(train_dfs[0])\n",
    "val_dataset = RainforestDataset(val_dfs[0])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = td.RandomSampler(train_dataset))\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = td.RandomSampler(val_dataset))\n",
    "\n",
    "training_loop(train_loader, val_loader, model, optimizer, scheduler, loss_function, e_poch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1c1f7",
   "metadata": {},
   "source": [
    "### Submission Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edf5a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_spectograms(file):\n",
    "    wav, sr = librosa.load(data_path + \"test/{}\".format(file), sr=None)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(wav, n_fft=fft, hop_length=hop, sr=sr)    \n",
    "    \n",
    "    preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(320),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    \n",
    "    current_mspec = (Image.fromarray(mel_spec, 'RGB'))\n",
    "  \n",
    "    current_mspec = preprocess(current_mspec)\n",
    "    \n",
    "    return current_mspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7047657f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n",
      "Starting prediction loop\n",
      "1992\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [32, 3, 3, 3], but got 3-dimensional input of size [3, 320, 320] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25457/984122781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Taking max prediction from all slices per bird species\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/resnest/torch/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 443\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [32, 3, 3, 3], but got 3-dimensional input of size [3, 320, 320] instead"
     ]
    }
   ],
   "source": [
    "# Model class definition \n",
    "model = resnest50(pretrained=False)\n",
    "\n",
    "model = torch.load('best_model_resnest.pth')\n",
    "model.eval()\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "# load model into GPU\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda available')\n",
    "    model.cuda()\n",
    "    \n",
    "# Prediction loop\n",
    "print('Starting prediction loop')\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    submission_writer = csv.writer(csvfile, delimiter=',')\n",
    "    submission_writer.writerow(['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n",
    "                               's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n",
    "    \n",
    "    test_files = os.listdir(data_path + 'test/') \n",
    "    print(len(test_files))\n",
    "    \n",
    "    # Every test file is split on several chunks and prediction is made for each chunk\n",
    "    for i in range(0, len(test_files)):\n",
    "        data = create_mel_spectograms(test_files[i])\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        # Taking max prediction from all slices per bird species\n",
    "        # Usually you want Sigmoid layer here to convert output to probabilities\n",
    "        # In this competition only relative ranking matters, and not the exact value of prediction, so we can use it directly\n",
    "        maxed_output = torch.max(output, dim=0)[0]\n",
    "        maxed_output = maxed_output.cpu().detach()\n",
    "        \n",
    "        file_id = str.split(test_files[i], '.')[0]\n",
    "        write_array = [file_id]\n",
    "        \n",
    "        for out in maxed_output:\n",
    "            write_array.append(out.item())\n",
    "    \n",
    "        submission_writer.writerow(write_array)\n",
    "        \n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print('Predicted for ' + str(i) + ' of ' + str(len(test_files) + 1) + ' files')\n",
    "\n",
    "print('Submission generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa76c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf7663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
