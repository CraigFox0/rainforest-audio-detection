{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ba842dda-e473-4329-aa3b-e819bd1e05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import soundfile as sf \n",
    "import librosa\n",
    "from skimage.transform import resize \n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader \n",
    "import torch.utils.data as td\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.utils.data as td \n",
    "\n",
    "# Setting seeds for reproducible results \n",
    "rng_seed = 1234\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_species = 24\n",
    "batch_size = 8\n",
    "\n",
    "fft = 2048\n",
    "hop = 512 \n",
    "# According to research, standard sampling bitrate is 48khz. Seen in discussion of kaggle competition as well. \n",
    "sr = 48000\n",
    "length = 10*sr\n",
    "# ResNet50 input layer is 224 x 224 x 3, so I'm resizing the image to fit the first input dimension. \n",
    "mel_spec_dimensions = (224,224)\n",
    "\n",
    "data_path = '/Users/Benra/ProjectData/Data/'\n",
    "\n",
    "df = pd.read_csv(data_path + 'train_tp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e38d5-436f-4a9d-bdb0-4f16058010a9",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790ae1c-8353-4566-9d52-f482a341ca8d",
   "metadata": {},
   "source": [
    "Just using a quick technique for now, worried only about getting model results back. Will use different preprocessing steps as we move on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5735bff2-4e1c-4699-b638-683f152f6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_spectograms(df):\n",
    "\n",
    "    df['spec'] = np.nan\n",
    "    df['spec'] = df['spec'].astype(object)\n",
    "\n",
    "    for idx,row in df.iterrows():\n",
    "\n",
    "        rid = row['recording_id']\n",
    "\n",
    "        wav, sr = librosa.load(data_path + 'train/' + rid + '.flac', sr=None)\n",
    "\n",
    "        # Slicing and centering spectograms \n",
    "        m = np.round((row['t_min'] + row['t_max']) / 2)\n",
    "        l = m - length / 2\n",
    "        if l < 0: l = 0\n",
    "        r = m + length\n",
    "        if r > len(wav):\n",
    "            r = len(wav)\n",
    "            l = r - m\n",
    "\n",
    "        mspec = librosa.feature.melspectrogram(y=wav[int(l):int(r)], n_fft=fft, hop_length=hop, sr=sr)\n",
    "        mspec = resize(mspec, mel_spec_dimensions)\n",
    "        mspec = (mspec - np.min(mspec))/np.max(mspec)\n",
    "\n",
    "        df.at[idx, 'spec'] = mspec\n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e21cc00a-ad40-4342-815f-9282d66b6f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>[[0.015004913, 0.0068973857, 0.004454195, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>[[0.0087603675, 0.02798395, 0.066221, 0.022382...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>[[0.093255796, 0.2414336, 0.07836443, 0.084347...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>[[0.07390476, 0.086226314, 0.07434976, 0.11918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>[[0.12386004, 0.03262526, 0.018277623, 0.01870...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recording_id  species_id  songtype_id    t_min     f_min    t_max     f_max  \\\n",
       "0    003bec244          14            1  44.5440  2531.250  45.1307   5531.25   \n",
       "1    006ab765f          23            1  39.9615  7235.160  46.0452  11283.40   \n",
       "2    007f87ba2          12            1  39.1360   562.500  42.2720   3281.25   \n",
       "3    0099c367b          17            4  51.4206  1464.260  55.1996   4565.04   \n",
       "4    009b760e6          10            1  50.0854   947.461  52.5293  10852.70   \n",
       "\n",
       "                                                spec  \n",
       "0  [[0.015004913, 0.0068973857, 0.004454195, 0.00...  \n",
       "1  [[0.0087603675, 0.02798395, 0.066221, 0.022382...  \n",
       "2  [[0.093255796, 0.2414336, 0.07836443, 0.084347...  \n",
       "3  [[0.07390476, 0.086226314, 0.07434976, 0.11918...  \n",
       "4  [[0.12386004, 0.03262526, 0.018277623, 0.01870...  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_mel_spectograms(df)\n",
    "df.to_csv('./Data/train_spectograms.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fedf57-304f-41c8-96fd-52e48e42a7b1",
   "metadata": {},
   "source": [
    "### Creating PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dee5c6-600e-4653-9d98-9e8fc2569f35",
   "metadata": {},
   "source": [
    "Note: Have to stack the spectrograms so that they're (224 x 224 x 3) to fit the input dimensions of ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6a79ff8e-646d-4408-a7c5-081beee62e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFCXDatasetFromArr(td.Dataset):\n",
    "    def __init__(self, df):\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "                \n",
    "        labels = df['species_id'].to_list()\n",
    "        for label in labels:\n",
    "            label_arr = np.zeros(24, dtype=np.single)\n",
    "            label_arr[label] = 1.\n",
    "            self.labels.append(label_arr)\n",
    "            \n",
    "        specs = df['spec'].to_numpy() \n",
    "        for i in range(len(specs)):\n",
    "            current_spec = np.array(specs[i])\n",
    "            stack = np.stack([current_spec, current_spec, current_spec])\n",
    "            self.data.append(stack)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ef2b9-8a3a-4c54-bfaa-1d2da6a37837",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "94cbc71b-5011-4a5f-8a10-088b7fc79298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = None\n",
    "val_df = None\n",
    "\n",
    "X = df.drop('species_id', axis=1)\n",
    "y = df['species_id']\n",
    "\n",
    "strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng_seed)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(strat.split(X,y)):\n",
    "    if fold==0:\n",
    "        train_df = df.iloc[train_index]\n",
    "        val_df = df.iloc[val_index]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ff776c47-726b-4e40-ad2f-3f77f529aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RFCXDatasetFromArr(train_df)\n",
    "val_dataset = RFCXDatasetFromArr(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705cf8a-8b5f-4012-98f6-195c702627d5",
   "metadata": {},
   "source": [
    "### Configuring Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757fbdb6-cd40-4377-ac64-7e595960ecd5",
   "metadata": {},
   "source": [
    "ResNet50 Research Reference: https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#data-augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d8d59-d5e4-44f8-b34c-e0478d9fe546",
   "metadata": {},
   "source": [
    "After reading up on ResNet at the above link, SGD was recommended as an optimizer. Went with a recommended learning rate scheduler from a related notebook in Kaggle. The above link recommends a different scheduler. We chose to use BCE w/ Logits Loss also based on recommendations from related work. We plan on trying out multiple different loss functions to see what works best for our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6c456c6e-a476-4bbb-a4ad-a0d227711ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = td.RandomSampler(train_dataset))\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = td.RandomSampler(val_dataset))\n",
    "\n",
    "# Model definition \n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight = torch.ones(num_species) * num_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e913cff-9d7a-4e70-8354-4f852a091d28",
   "metadata": {},
   "source": [
    "Below, we can see the shape of our model. Note that ResNet50 has an output dimension of 2048, which we pass through a fully connected layer. The output of our fc layer is in agreement with competition standards. We designed the FC layer based on related work, and will optimize it in later phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4e35d027-4485-455b-95e9-c3397e98858f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=1024, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f0efa-98bc-4d2e-ab83-f99dc400c77e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54d7b8-6d82-4594-bf6a-670e0041cd15",
   "metadata": {},
   "source": [
    "Training loop based on the work of another Kaggle notebook: https://www.kaggle.com/fffrrt/all-in-one-rfcx-baseline-for-beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833d7b5-c255-435b-bb45-683ee6032514",
   "metadata": {},
   "source": [
    "Maintains a validation accuracy statistic (Does the most probable class match the ground-truth label?) as the model trains, and saves the model with the highest validation accuracy to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b35eb353-32f5-4ff2-ade3-f2656c42be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_loader, val_loader, model, optimizer, scheduler, loss_function):\n",
    "    best_corrects = 0\n",
    "\n",
    "\n",
    "    for e in range(0, 8):\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            lr = g['lr']\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Training Loss: \", str(sum(train_loss) / len(train_loss)))\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_corr = []\n",
    "\n",
    "            model.eval()\n",
    "            for batch, (data, target) in enumerate(val_loader):\n",
    "                data = data.float()\n",
    "                if torch.cuda.is_available():\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                output = model(data)\n",
    "                loss = loss_function(output, target)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                vals, answers = torch.max(output, 1)\n",
    "                vals, targets = torch.max(target, 1)\n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "                val_corr.append(corrects)\n",
    "\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Validation Loss: \", str(sum(val_loss) / len(val_loss)))\n",
    "\n",
    "\n",
    "        if sum(val_corr) > best_corrects:\n",
    "            print('Saving new best model at epoch ' + str(e) + ' (' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()) + ')')\n",
    "            torch.save(model, 'best_model.pt')\n",
    "            best_corrects = sum(val_corr)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    del model\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e90d7ad4-0d75-4ba6-baf5-f01790b6955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weights, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a6e2d-ced8-4f89-b371-665cd85cd720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
