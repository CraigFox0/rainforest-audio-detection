{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b878a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import soundfile as sf \n",
    "import librosa\n",
    "from skimage.transform import resize \n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader \n",
    "import torch.utils.data as td\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.utils.data as td\n",
    "import pywt\n",
    "\n",
    "\n",
    "\n",
    "# Setting seeds for reproducible results \n",
    "rng_seed = 1234\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_species = 24\n",
    "batch_size = 32\n",
    "\n",
    "fft = 2048\n",
    "hop = 512 \n",
    "# According to research, standard sampling bitrate is 48khz. Seen in discussion of kaggle competition as well. \n",
    "sr = 48000\n",
    "length = 10*sr\n",
    "# ResNet50 input layer is 224 x 224 x 3, so I'm resizing the image to fit the first input dimension. \n",
    "mel_spec_dimensions = (224,224)\n",
    "\n",
    "data_path = '../Data/'\n",
    "\n",
    "preproc_type = 'spec'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0bdc9",
   "metadata": {},
   "source": [
    "### Cuda Device Selection\n",
    "\n",
    "Use cuda:{device_num} to select cuda device that is not being used already\n",
    "\n",
    "Make sure that this device is selected by exporting CUDA_VISIBLE_DEVICES={device_num} on the shell that's running the notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605dd2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 31 16:09:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   53C    P0   267W / 300W |  14448MiB / 16384MiB |     69%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    71W / 300W |  12485MiB / 16384MiB |     31%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   63C    P0   244W / 300W |  10617MiB / 16384MiB |     90%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   300W / 300W |  15547MiB / 16384MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   52C    P0   229W / 300W |  10194MiB / 16384MiB |     97%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    45W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   29C    P0    42W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    41W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      9506      C   /usr/bin/python                  8613MiB |\n",
      "|    0   N/A  N/A     79889      C   ...a3/envs/hwr/bin/python3.9     4229MiB |\n",
      "|    0   N/A  N/A     79910      C   ...da3/envs/EAST3/bin/python     1601MiB |\n",
      "|    1   N/A  N/A     28835      C   python3                          6241MiB |\n",
      "|    1   N/A  N/A     29618      C   python3                          6241MiB |\n",
      "|    2   N/A  N/A     39072      C   /usr/bin/python                  5199MiB |\n",
      "|    2   N/A  N/A     43189      C   /usr/bin/python                  5415MiB |\n",
      "|    3   N/A  N/A     16113      C   /usr/bin/python                  6301MiB |\n",
      "|    3   N/A  N/A     58436      C   python                           9243MiB |\n",
      "|    4   N/A  N/A      2297      C   python                          10191MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e5ebb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492d2297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/\n"
     ]
    }
   ],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d793b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path + 'train_Augmented.csv') #File Containing the Spectograms as String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb252f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1216, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf684cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to2DArray(x): \n",
    "    x=x.replace(\"[\", '')\n",
    "    x=x.replace(\"]\", '')\n",
    "    x=x.replace(\"...\", '')\n",
    "    x=x.replace(\"\\n\", '')\n",
    "    y=np.array(x.split(\" \"))\n",
    "    y = y[y != \"\"]\n",
    "    y = np.asfarray(y, 'float64')\n",
    "    y = np.reshape(y,(1, y.size))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa59cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[preproc_type] = df[preproc_type].apply(lambda x: to2DArray(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5beb48",
   "metadata": {},
   "source": [
    "### Creating PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9dde95",
   "metadata": {},
   "source": [
    "Note: Have to stack the spectrograms so that they're (224 x 224 x 3) to fit the input dimensions of ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566df713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFCXDatasetFromArr(td.Dataset):\n",
    "    def __init__(self, df, preproc_type):\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "         # need this to transform data to tensors    \n",
    "        self.transform = transforms.ToTensor()\n",
    "                \n",
    "        labels = df['species_id'].to_list()\n",
    "        for label in labels:\n",
    "            label_arr = np.zeros(24, dtype=np.single)\n",
    "            label_arr[label] = 1.\n",
    "            self.labels.append(label_arr)\n",
    "             \n",
    "        specs = df[preproc_type]\n",
    "#         print(specs)\n",
    "            \n",
    "        for spec in specs:\n",
    "            stack = np.stack([spec, spec, spec])\n",
    "            self.data.append(stack)\n",
    "            \n",
    "            \n",
    "#         for i in range(len(specs)):\n",
    "#             current_spec = np.array(specs[i])\n",
    "#             dwt_decomp = pywt.dwt2(current_spec, 'bior1.3')\n",
    "#             LL, (LH, HL, HH) = dwt_decomp\n",
    "#             stack = np.stack([LH, HL, HH])\n",
    "#             self.data.append((LH, HL, HH))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.data[idx]), torch.tensor(self.labels[idx]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b929c",
   "metadata": {},
   "source": [
    "### Configuring Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6080ad",
   "metadata": {},
   "source": [
    "ResNet50 Research Reference: https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#data-augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5856132",
   "metadata": {},
   "source": [
    "After reading up on ResNet at the above link, SGD was recommended as an optimizer. Went with a recommended learning rate scheduler from a related notebook in Kaggle. The above link recommends a different scheduler. We chose to use BCE w/ Logits Loss also based on recommendations from related work. We plan on trying out multiple different loss functions to see what works best for our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ddb50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Model definition \n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "# load model into GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236be2fb",
   "metadata": {},
   "source": [
    "Below, we can see the shape of our model. Note that ResNet50 has an output dimension of 2048, which we pass through a fully connected layer. The output of our fc layer is in agreement with competition standards. We designed the FC layer based on related work, and will optimize it in later phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551190f",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6a613",
   "metadata": {},
   "source": [
    "As per Abha's request, we're trying out EfficientNet here. The main advantages for us of using EfficientNet are that it is built to parallelize more efficiently and runs faster than ResNet50. It also has been shown that it is effective on other CV tasks, so it's worth a shot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe8de14",
   "metadata": {},
   "source": [
    "There are 8 different EfficientNet variations. Each one takes the same input dimensionality as ResNet50, but the output classifier has different dimensions in each variation. Here we use the most complex model, EfficientNet-B7. The classifier for this model uses a linear activation layer that outputs our 24 probabilistic classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa3a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet = models.efficientnet_b7(pretrained=True)\n",
    "effnet.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=2560, out_features=24, bias=True),\n",
    ")\n",
    "\n",
    "effnet = effnet.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a9ccd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=2560, out_features=24, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnet.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d4a82",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b2a5e",
   "metadata": {},
   "source": [
    "Training loop based on the work of another Kaggle notebook: https://www.kaggle.com/fffrrt/all-in-one-rfcx-baseline-for-beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8b646",
   "metadata": {},
   "source": [
    "Maintains a validation accuracy statistic (Does the most probable class match the ground-truth label?) as the model trains, and saves the model with the highest validation accuracy to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdc4aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function, max_epochs, highest_score):\n",
    "    best_corrects = highest_score\n",
    "    \n",
    "    for e in range(0, max_epochs):\n",
    "        train_loss = []\n",
    "        \n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output = output.cuda()\n",
    "            \n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            lr = g['lr']\n",
    "            \n",
    "        # Train Results\n",
    "        print(\"====TRAIN====\")\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Training Loss: \", str(sum(train_loss) / len(train_loss)))\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_corr = []\n",
    "\n",
    "            model.eval()\n",
    "            for batch, (data, target) in enumerate(val_loader):\n",
    "                data = data.float()\n",
    "                if torch.cuda.is_available():\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                output = model(data)\n",
    "                loss = loss_function(output, target)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                vals, answers = torch.max(output, 1)\n",
    "                vals, targets = torch.max(target, 1)\n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "                val_corr.append(corrects)\n",
    "\n",
    "        # Val Results \n",
    "        \n",
    "        print(\"====VAL====\")\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Validation Loss: \", str(sum(val_loss) / len(val_loss)))\n",
    "\n",
    "\n",
    "        if sum(val_corr) > best_corrects:\n",
    "            print('Saving new best model at epoch ' + str(e) + ' (' + str(sum(val_corr)) + '/' + str(len(val_loader.dataset)) + ')')\n",
    "            torch.save(model, f'best_model_{model.__class__.__name__}.pt')\n",
    "            best_corrects = sum(val_corr)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    del model\n",
    "    \n",
    "    return best_corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c33d781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training_loop(train_loader, val_loader, effnet, optimizer, scheduler, pos_weight, loss_function, 32, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c425703",
   "metadata": {},
   "source": [
    "### Setting Up Cross Validation Loop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df14e43",
   "metadata": {},
   "source": [
    "Use this code cell to test hyperparameters using 5-fold cross validation. Just have to put list of 5 CV parameters in the specified location and change the parameters to variables in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b40d561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV FOLD  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24305/2988992121.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mloss_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighest_correct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhighest_correct\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24305/2533135708.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function, max_epochs, highest_score)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 443\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "effnet = models.efficientnet_b7(pretrained=True)\n",
    "effnet.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=2560, out_features=24, bias=True),\n",
    ")\n",
    "\n",
    "effnet = effnet.to('cuda')\n",
    "\n",
    "\n",
    "train_df = None\n",
    "val_df = None\n",
    "\n",
    "X = df.drop('species_id', axis=1)\n",
    "y = df['species_id']\n",
    "\n",
    "strat = StratifiedKFold(n_splits=3, shuffle=True, random_state=rng_seed)\n",
    "\n",
    "highest_correct = 0\n",
    "\n",
    "### INSERT CV PARAMETERS HERE ### \n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "\n",
    "## Make sure to change cv parameters to variables in for loop as well (e.g. lr = possible_lr_values[fold])\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(strat.split(X,y)):\n",
    "    print(\"CV FOLD \", fold)\n",
    "    \n",
    "    train_df = df.iloc[train_index].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_index].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = RFCXDatasetFromArr(train_df, preproc_type)\n",
    "    val_dataset = RFCXDatasetFromArr(val_df, preproc_type)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = td.RandomSampler(train_dataset))\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = td.RandomSampler(val_dataset))\n",
    "\n",
    "    # Need to add in loss, optimizer and scheduler, set up cv for the different folds \n",
    "    pos_weight = (torch.ones(num_species) * num_species)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(effnet.parameters(), lr=0.0001, weight_decay=0.01, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    loss_function = nn.BCEWithLogitsLoss(pos_weight)\n",
    "    loss_function.to('cuda')\n",
    "    \n",
    "    best_score = training_loop(train_loader, val_loader, effnet, optimizer, scheduler, pos_weight, loss_function, 16, highest_correct)\n",
    "    \n",
    "    if best_score > highest_correct: \n",
    "        highest_correct = best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5788e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1af73c2",
   "metadata": {},
   "source": [
    "### Generating Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be64a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split for submission \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.15, stratify=df['species_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf162d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e1a1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RFCXDatasetFromArr(train, preproc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5288007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Epoch  1\n",
      "Epoch  2\n",
      "Epoch  3\n",
      "Epoch  4\n",
      "Epoch  5\n",
      "Epoch  6\n",
      "Epoch  7\n",
      "Epoch  8\n",
      "Epoch  9\n",
      "Epoch  10\n",
      "Epoch  11\n",
      "Epoch  12\n",
      "Epoch  13\n",
      "Epoch  14\n",
      "Epoch  15\n",
      "Epoch  16\n",
      "Epoch  17\n",
      "Epoch  18\n",
      "Epoch  19\n",
      "Epoch  20\n",
      "Epoch  21\n",
      "Epoch  22\n",
      "Epoch  23\n",
      "Epoch  24\n",
      "Epoch  25\n",
      "Epoch  26\n",
      "Epoch  27\n",
      "Epoch  28\n",
      "Epoch  29\n",
      "Epoch  30\n",
      "Epoch  31\n"
     ]
    }
   ],
   "source": [
    "# train_df = df.iloc[train_index].reset_index(drop=True)\n",
    "# val_df = df.iloc[val_index].reset_index(drop=True)\n",
    "\n",
    "# train_dataset = RFCXDatasetFromArr(train_df, preproc_type)\n",
    "# val_dataset = RFCXDatasetFromArr(val_df, preproc_type)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = td.RandomSampler(train_dataset))\n",
    "# val_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = td.RandomSampler(val_dataset))\n",
    "\n",
    "# Need to add in loss, optimizer and scheduler, set up cv for the different folds \n",
    "pos_weight = pos_weight = (torch.ones(num_species) * num_species)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight)\n",
    "loss_function.to('cuda')\n",
    "\n",
    "# best_score = training_loop(train_loader, val_loader, effnet, optimizer, scheduler, pos_weight, loss_function, 32, highest_correct)\n",
    "\n",
    "\n",
    "for e in range(0, 32):\n",
    "    print(\"Epoch \", e)\n",
    "    train_loss = []\n",
    "\n",
    "    effnet.train()\n",
    "    for batch, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.to('cuda'), target.to('cuda')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = effnet(data)\n",
    "        output = output.cuda()\n",
    "\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "    for g in optimizer.param_groups:\n",
    "        lr = g['lr']\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "torch.save(effnet, f'effnet_baseline.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6a1bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "077288e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RFCXDatasetFromArr(test, preproc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4308ba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_spectograms(df):\n",
    "    wav, sr = librosa.load(\"../../Data/test/{}\".format(df), sr=None)\n",
    "\n",
    "    # Split for enough segments to not miss anything\n",
    "    segments = len(wav) / length\n",
    "    segments = int(np.ceil(segments))\n",
    "    \n",
    "    mel_array = []\n",
    "    \n",
    "    for i in range(0, segments):\n",
    "        # Last segment going from the end\n",
    "        if (i + 1) * length > len(wav):\n",
    "            slice = wav[len(wav) - length:len(wav)]\n",
    "        else:\n",
    "            slice = wav[i * length:(i + 1) * length]\n",
    "        \n",
    "        # Same mel spectrogram as before\n",
    "        mel_spec = librosa.feature.melspectrogram(slice, n_fft=fft, hop_length=hop, sr=sr)\n",
    "        mel_spec = resize(mel_spec, mel_spec_dimensions)\n",
    "    \n",
    "        mel_spec = mel_spec - np.min(mel_spec)\n",
    "        mel_spec = mel_spec / np.max(mel_spec)\n",
    "        \n",
    "        mel_spec = np.stack((mel_spec, mel_spec, mel_spec))\n",
    "\n",
    "        mel_array.append(mel_spec)\n",
    "    \n",
    "    return mel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb6a54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction loop\n",
      "1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24305/2847652499.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:207.)\n",
      "  data = torch.tensor(data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted for 100 of 1993 files\n",
      "Predicted for 200 of 1993 files\n",
      "Predicted for 300 of 1993 files\n",
      "Predicted for 400 of 1993 files\n",
      "Predicted for 500 of 1993 files\n",
      "Predicted for 600 of 1993 files\n",
      "Predicted for 700 of 1993 files\n",
      "Predicted for 800 of 1993 files\n",
      "Predicted for 900 of 1993 files\n",
      "Predicted for 1000 of 1993 files\n",
      "Predicted for 1100 of 1993 files\n",
      "Predicted for 1200 of 1993 files\n",
      "Predicted for 1300 of 1993 files\n",
      "Predicted for 1400 of 1993 files\n",
      "Predicted for 1500 of 1993 files\n",
      "Predicted for 1600 of 1993 files\n",
      "Predicted for 1700 of 1993 files\n",
      "Predicted for 1800 of 1993 files\n",
      "Predicted for 1900 of 1993 files\n",
      "Submission generated\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "model = torch.load('./best_models/66-406/best_model_EfficientNet.pt')\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Prediction loop\n",
    "print('Starting prediction loop')\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    submission_writer = csv.writer(csvfile, delimiter=',')\n",
    "    submission_writer.writerow(['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n",
    "                               's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n",
    "    \n",
    "    test_files = os.listdir('../../Data/test/') \n",
    "    print(len(test_files))\n",
    "    \n",
    "    # Every test file is split on several chunks and prediction is made for each chunk\n",
    "    for i in range(0, len(test_files)):\n",
    "        data = create_mel_spectograms(test_files[i])\n",
    "        data = torch.tensor(data)\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        # Taking max prediction from all slices per bird species\n",
    "        # Usually you want Sigmoid layer here to convert output to probabilities\n",
    "        # In this competition only relative ranking matters, and not the exact value of prediction, so we can use it directly\n",
    "        maxed_output = torch.max(output, dim=0)[0]\n",
    "        maxed_output = maxed_output.cpu().detach()\n",
    "        \n",
    "        file_id = str.split(test_files[i], '.')[0]\n",
    "        write_array = [file_id]\n",
    "        \n",
    "        for out in maxed_output:\n",
    "            write_array.append(out.item())\n",
    "    \n",
    "        submission_writer.writerow(write_array)\n",
    "        \n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print('Predicted for ' + str(i) + ' of ' + str(len(test_files) + 1) + ' files')\n",
    "\n",
    "print('Submission generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a231db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ed428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
