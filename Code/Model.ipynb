{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import soundfile as sf \n",
    "import librosa\n",
    "from skimage.transform import resize \n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader \n",
    "import torch.utils.data as td\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.utils.data as td \n",
    "# Setting seeds for reproducible results \n",
    "rng_seed = 1234\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_species = 24\n",
    "batch_size = 8\n",
    "\n",
    "fft = 2048\n",
    "hop = 512 \n",
    "# According to research, standard sampling bitrate is 48khz. Seen in discussion of kaggle competition as well. \n",
    "sr = 48000\n",
    "length = 10*sr\n",
    "# ResNet50 input layer is 224 x 224 x 3, so I'm resizing the image to fit the first input dimension. \n",
    "mel_spec_dimensions = (224,224)\n",
    "\n",
    "data_path = '../Data/'\n",
    "\n",
    "df = pd.read_csv(data_path + 'train_tp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9e988",
   "metadata": {},
   "source": [
    "### Cuda Device Selection\n",
    "\n",
    "Use cuda:{device_num} to select cuda device that is not being used already\n",
    "\n",
    "Make sure that this device is selected by exporting CUDA_VISIBLE_DEVICES={device_num} on the shell that's running the notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
=======
   "id": "f7e449b2",
>>>>>>> philgen
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar  7 13:09:28 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   25C    P0    41W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    80W / 300W |  15220MiB / 16384MiB |     33%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   24C    P0    42W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   23C    P0    41W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    57W / 300W |   3606MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   26C    P0    43W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    62W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   54C    P0   262W / 300W |  12610MiB / 16384MiB |     98%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     77369      C   python                          15217MiB |\n",
      "|    4   N/A  N/A     68537      C   ...da3/envs/EAST3/bin/python     3603MiB |\n",
      "|    7   N/A  N/A     74151      C   python                          12607MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4d85c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just using a quick technique for now, worried only about getting model results back. Will use different preprocessing steps as we move on. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 4,
   "id": "5735bff2-4e1c-4699-b638-683f152f6294",
>>>>>>> philgen
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_spectograms(df):\n",
    "    df['spec'] = np.nan\n",
    "    df['spec'] = df['spec'].astype(object)\n",
    "    \n",
    "    for idx,row in df.iterrows():\n",
    "        \n",
    "        rid = row['recording_id']\n",
    "\n",
    "        wav, sr = librosa.load(data_path + 'train/' + rid + '.flac', sr=None)\n",
    "\n",
    "        # Slicing and centering spectograms \n",
    "        m = np.round((row['t_min'] + row['t_max']) / 2)\n",
    "        l = m - length / 2\n",
    "        if l < 0: l = 0\n",
    "        r = m + length\n",
    "        if r > len(wav):\n",
    "            r = len(wav)\n",
    "            l = r - m\n",
    "\n",
    "        mspec = librosa.feature.melspectrogram(y=wav[int(l):int(r)], n_fft=fft, hop_length=hop, sr=sr)\n",
    "        mspec = resize(mspec, mel_spec_dimensions)\n",
    "        mspec = (mspec - np.min(mspec))/np.max(mspec)\n",
    "            \n",
    "        df.at[idx, 'spec'] = mspec\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e6d49",
   "metadata": {},
   "source": [
    "### Optional: Rerun Mel Spectogram Pipeline \n",
    "\n",
    "Note: should not be necessary if up to date with main branch\n",
    "train_spectograms.csv should already be saved at Data/train_spectograms.csv, though we might need to pickle the spec 2d array so that we can retrieve it for the model\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
   "id": "e21cc00a-ad40-4342-815f-9282d66b6f81",
>>>>>>> philgen
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording_id     object\n",
      "species_id        int64\n",
      "songtype_id       int64\n",
      "t_min           float64\n",
      "f_min           float64\n",
      "t_max           float64\n",
      "f_max           float64\n",
      "spec             object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>[[0.015969152, 0.0068952353, 0.004454193, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>[[0.00960646, 0.027989434, 0.066221, 0.0223827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>[[0.09593078, 0.24144638, 0.07836443, 0.084347...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>[[0.10142235, 0.08636865, 0.07434975, 0.119185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>[[0.1255407, 0.032630917, 0.01827762, 0.018702...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  recording_id  species_id  songtype_id    t_min     f_min    t_max     f_max  \\\n",
       "0    003bec244          14            1  44.5440  2531.250  45.1307   5531.25   \n",
       "1    006ab765f          23            1  39.9615  7235.160  46.0452  11283.40   \n",
       "2    007f87ba2          12            1  39.1360   562.500  42.2720   3281.25   \n",
       "3    0099c367b          17            4  51.4206  1464.260  55.1996   4565.04   \n",
       "4    009b760e6          10            1  50.0854   947.461  52.5293  10852.70   \n",
       "\n",
       "                                                spec  \n",
       "0  [[0.015969152, 0.0068952353, 0.004454193, 0.00...  \n",
       "1  [[0.00960646, 0.027989434, 0.066221, 0.0223827...  \n",
       "2  [[0.09593078, 0.24144638, 0.07836443, 0.084347...  \n",
       "3  [[0.10142235, 0.08636865, 0.07434975, 0.119185...  \n",
       "4  [[0.1255407, 0.032630917, 0.01827762, 0.018702...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_mel_spectograms(df)\n",
    "df.to_csv(data_path + 'train_spectograms.csv')\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fecc17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.at[1, 'spec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Have to stack the spectrograms so that they're (224 x 224 x 3) to fit the input dimensions of ResNet50"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 7,
   "id": "6a79ff8e-646d-4408-a7c5-081beee62e33",
>>>>>>> philgen
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFCXDatasetFromArr(td.Dataset):\n",
    "    def __init__(self, df):\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "         # need this to transform data to tensors    \n",
    "        self.transform = transforms.ToTensor()\n",
    "                \n",
    "        labels = df['species_id'].to_list()\n",
    "        for label in labels:\n",
    "            label_arr = np.zeros(24, dtype=np.single)\n",
    "            label_arr[label] = 1.\n",
    "            self.labels.append(label_arr)\n",
    "             \n",
    "        specs = df['spec']\n",
    "            \n",
    "        for i in range(len(specs)):\n",
    "            current_spec = np.array(specs[i])\n",
    "            stack = np.stack([current_spec, current_spec, current_spec])\n",
    "            self.data.append(stack)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.data[idx]), torch.tensor(self.labels[idx]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 8,
   "id": "94cbc71b-5011-4a5f-8a10-088b7fc79298",
>>>>>>> philgen
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = None\n",
    "val_df = None\n",
    "\n",
    "# df = pd.read_csv(data_path + 'train_spectograms.csv')\n",
    "X = df.drop('species_id', axis=1)\n",
    "y = df['species_id']\n",
    "\n",
    "strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng_seed)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(strat.split(X,y)):\n",
    "    if fold==0:\n",
    "        train_df = df.iloc[train_index]\n",
    "        val_df = df.iloc[val_index]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 9,
   "id": "ff776c47-726b-4e40-ad2f-3f77f529aad8",
>>>>>>> philgen
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RFCXDatasetFromArr(train_df)\n",
    "val_dataset = RFCXDatasetFromArr(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 Research Reference: https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#data-augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading up on ResNet at the above link, SGD was recommended as an optimizer. Went with a recommended learning rate scheduler from a related notebook in Kaggle. The above link recommends a different scheduler. We chose to use BCE w/ Logits Loss also based on recommendations from related work. We plan on trying out multiple different loss functions to see what works best for our problem. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 10,
   "id": "6c456c6e-a476-4bbb-a4ad-a0d227711ddd",
>>>>>>> philgen
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = td.RandomSampler(train_dataset))\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = td.RandomSampler(val_dataset))\n",
    "\n",
    "# Model definition \n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "pos_weight = (torch.ones(num_species) * num_species)\n",
    "\n",
    "# load model into GPU\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight)\n",
    "\n",
    "loss_function.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see the shape of our model. Note that ResNet50 has an output dimension of 2048, which we pass through a fully connected layer. The output of our fc layer is in agreement with competition standards. We designed the FC layer based on related work, and will optimize it in later phases."
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model into GPU\n",
    "model = model.to(device)"
   ]
  },
  {
=======
>>>>>>> philgen
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop based on the work of another Kaggle notebook: https://www.kaggle.com/fffrrt/all-in-one-rfcx-baseline-for-beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintains a validation accuracy statistic (Does the most probable class match the ground-truth label?) as the model trains, and saves the model with the highest validation accuracy to the project directory."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 12,
   "id": "b35eb353-32f5-4ff2-ade3-f2656c42be5f",
>>>>>>> philgen
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function):\n",
    "    best_corrects = 0\n",
    "\n",
    "\n",
    "    for e in range(0, 8):\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader):\n",
    "\n",
    "#             print(data.shape)\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "#                 print(\"Loading training data to device\")\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output = output.cuda()\n",
    "            \n",
    "            loss = loss_function(output, target)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            lr = g['lr']\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Training Loss: \", str(sum(train_loss) / len(train_loss)))\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_corr = []\n",
    "\n",
    "            model.eval()\n",
    "            for batch, (data, target) in enumerate(val_loader):\n",
    "                data = data.float()\n",
    "                if torch.cuda.is_available():\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "        \n",
    "                \n",
    "                output = model(data)\n",
    "                loss = loss_function(output, target)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                vals, answers = torch.max(output, 1)\n",
    "                vals, targets = torch.max(target, 1)\n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "                val_corr.append(corrects)\n",
    "\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Validation Loss: \", str(sum(val_loss) / len(val_loss)))\n",
    "\n",
    "\n",
    "        if sum(val_corr) > best_corrects:\n",
    "            print('Saving new best model at epoch ' + str(e) + ' (' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()) + ')')\n",
    "            torch.save(model, 'best_model.pt')\n",
    "            best_corrects = sum(val_corr)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    del model\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 13,
   "id": "e90d7ad4-0d75-4ba6-baf5-f01790b6955c",
>>>>>>> philgen
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.914899140107827\n",
      "Epoch:  0\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  3.9569982790177867\n",
      "Saving new best model at epoch 0 (16/244)\n",
      "Epoch:  1\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.147407179973165\n",
      "Epoch:  1\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  3.9579068383862896\n",
      "Saving new best model at epoch 1 (24/244)\n",
      "Epoch:  2\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  3.944097653764193\n",
      "Epoch:  2\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  3.7939306459119244\n",
      "Epoch:  3\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  3.9025530912837043\n",
      "Epoch:  3\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  3.6627739014164096\n",
      "Saving new best model at epoch 3 (41/244)\n",
      "Epoch:  4\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  3.810931248743026\n",
      "Epoch:  4\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  3.6661490855678434\n",
      "Epoch:  5\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  3.769280668164863\n",
      "Epoch:  5\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  3.6101249648678686\n",
      "Epoch:  6\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  3.6390663150881157\n",
      "Epoch:  6\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  3.5129523123464277\n",
      "Saving new best model at epoch 6 (58/244)\n",
      "Epoch:  7\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  3.407040138713649\n",
      "Epoch:  7\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  3.418763429887833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "48d42ecc",
>>>>>>> philgen
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
