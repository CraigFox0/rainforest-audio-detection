{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 61,
   "id": "ba842dda-e473-4329-aa3b-e819bd1e05f5",
>>>>>>> origin/j-huzar
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import soundfile as sf \n",
    "import librosa\n",
    "from skimage.transform import resize \n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader \n",
    "import torch.utils.data as td\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
<<<<<<< HEAD
    "import torch.utils.data as td\n",
    "import pywt\n",
=======
    "import torch.utils.data as td \n",
    "import csv\n",
>>>>>>> origin/j-huzar
    "# Setting seeds for reproducible results \n",
    "rng_seed = 1234\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_species = 24\n",
    "batch_size = 8\n",
    "\n",
    "data_path = '../Data/'\n",
    "\n",
<<<<<<< HEAD
    "df = pd.read_csv(data_path+'csv/'+'train_tp'+'_data.csv')"
=======
    "df = pd.read_csv(data_path + 'train_spectograms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "394b4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42dc27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9e988",
   "metadata": {},
   "source": [
    "### Cuda Device Selection\n",
    "\n",
    "Use cuda:{device_num} to select cuda device that is not being used already\n",
    "\n",
    "Make sure that this device is selected by exporting CUDA_VISIBLE_DEVICES={device_num} on the shell that's running the notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7e449b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 17 16:59:00 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    86W / 300W |   9945MiB / 16384MiB |     33%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    59W / 300W |   4972MiB / 16384MiB |     10%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    55W / 300W |   3759MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    79W / 300W |   2552MiB / 16384MiB |     87%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3722      C   python3                          4971MiB |\n",
      "|    0   N/A  N/A     22819      C   python3                          4971MiB |\n",
      "|    1   N/A  N/A      3491      C   python3                          4969MiB |\n",
      "|    2   N/A  N/A     14956      C   python                           1967MiB |\n",
      "|    2   N/A  N/A     32153      C   /opt/conda/bin/python3.8         1789MiB |\n",
      "|    3   N/A  N/A     25248      C   ./sGMRESv4_gpu                   2549MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi')"
>>>>>>> origin/j-huzar
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
=======
   "execution_count": 65,
   "id": "f4d85c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e38d5-436f-4a9d-bdb0-4f16058010a9",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790ae1c-8353-4566-9d52-f482a341ca8d",
   "metadata": {},
   "source": [
    "Just using a quick technique for now, worried only about getting model results back. Will use different preprocessing steps as we move on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5735bff2-4e1c-4699-b638-683f152f6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_mel_spectograms(df):\n",
    "#     df['spec'] = np.nan\n",
    "#     df['spec'] = df['spec'].astype(object)\n",
    "    \n",
    "#     for idx,row in df.iterrows():\n",
    "        \n",
    "#         rid = row['recording_id']\n",
    "\n",
    "#         wav, sr = librosa.load(data_path + 'train/' + rid + '.flac', sr=None)\n",
    "\n",
    "         # Slicing and centering spectograms \n",
    "#         m = np.round((row['t_min'] + row['t_max']) / 2)\n",
    "#         l = m - length / 2\n",
    "#         if l < 0: l = 0\n",
    "#         r = m + length\n",
    "#         if r > len(wav):\n",
    "#             r = len(wav)\n",
    "#             l = r - m\n",
    "\n",
    "#         mspec = librosa.feature.melspectrogram(y=wav[int(l):int(r)], n_fft=fft, hop_length=hop, sr=sr)\n",
    "#         mspec = resize(mspec, mel_spec_dimensions)\n",
    "#         mspec = (mspec - np.min(mspec))/np.max(mspec)\n",
    "            \n",
    "#         df.at[idx, 'spec'] = mspec\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e6d49",
   "metadata": {},
   "source": [
    "### Optional: Rerun Mel Spectogram Pipeline \n",
    "\n",
    "Note: should not be necessary if up to date with main branch\n",
    "train_spectograms.csv should already be saved at Data/train_spectograms.csv, though we might need to pickle the spec 2d array so that we can retrieve it for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6d563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21cc00a-ad40-4342-815f-9282d66b6f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = create_mel_spectograms(df)\n",
    "# df.to_csv(data_path + 'train_spectograms.csv')\n",
    "# print(df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bbd556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../../BatchNormalizedAudio.csv') #File Containing the Spectograms as String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e877b12",
   "metadata": {},
   "outputs": [
    {
>>>>>>> origin/j-huzar
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
<<<<<<< HEAD
=======
       "      <td>[[1.5969152e-02 6.8952353e-03 4.4541932e-03 .....</td>\n",
>>>>>>> origin/j-huzar
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
<<<<<<< HEAD
=======
       "      <td>[[9.6064601e-03 2.7989434e-02 6.6220999e-02 .....</td>\n",
>>>>>>> origin/j-huzar
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
<<<<<<< HEAD
=======
       "      <td>[[9.5930777e-02 2.4144638e-01 7.8364432e-02 .....</td>\n",
>>>>>>> origin/j-huzar
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
<<<<<<< HEAD
=======
       "      <td>[[0.10142235 0.08636865 0.07434975 ... 0.16675...</td>\n",
>>>>>>> origin/j-huzar
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
<<<<<<< HEAD
=======
       "      <td>[[1.25540704e-01 3.26309167e-02 1.82776209e-02...</td>\n",
>>>>>>> origin/j-huzar
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "  recording_id  species_id  songtype_id    t_min     f_min    t_max     f_max\n",
       "0    003bec244          14            1  44.5440  2531.250  45.1307   5531.25\n",
       "1    006ab765f          23            1  39.9615  7235.160  46.0452  11283.40\n",
       "2    007f87ba2          12            1  39.1360   562.500  42.2720   3281.25\n",
       "3    0099c367b          17            4  51.4206  1464.260  55.1996   4565.04\n",
       "4    009b760e6          10            1  50.0854   947.461  52.5293  10852.70"
      ]
     },
     "execution_count": 3,
=======
       "  recording_id  species_id  songtype_id    t_min     f_min    t_max     f_max  \\\n",
       "0    003bec244          14            1  44.5440  2531.250  45.1307   5531.25   \n",
       "1    006ab765f          23            1  39.9615  7235.160  46.0452  11283.40   \n",
       "2    007f87ba2          12            1  39.1360   562.500  42.2720   3281.25   \n",
       "3    0099c367b          17            4  51.4206  1464.260  55.1996   4565.04   \n",
       "4    009b760e6          10            1  50.0854   947.461  52.5293  10852.70   \n",
       "\n",
       "                                                spec  \n",
       "0  [[1.5969152e-02 6.8952353e-03 4.4541932e-03 .....  \n",
       "1  [[9.6064601e-03 2.7989434e-02 6.6220999e-02 .....  \n",
       "2  [[9.5930777e-02 2.4144638e-01 7.8364432e-02 .....  \n",
       "3  [[0.10142235 0.08636865 0.07434975 ... 0.16675...  \n",
       "4  [[1.25540704e-01 3.26309167e-02 1.82776209e-02...  "
      ]
     },
     "execution_count": 38,
>>>>>>> origin/j-huzar
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda Device Selection\n",
    "\n",
    "Use cuda:{device_num} to select cuda device that is not being used already\n",
    "\n",
    "Make sure that this device is selected by exporting CUDA_VISIBLE_DEVICES={device_num} on the shell that's running the notebook server"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 10 16:17:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   52C    P0   291W / 300W |  10042MiB / 16384MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   60C    P0   285W / 300W |  11206MiB / 16384MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   279W / 300W |  15720MiB / 16384MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    63W / 300W |  11598MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     27637      C   python                          10039MiB |\n",
      "|    1   N/A  N/A     24201      C   python                          11201MiB |\n",
      "|    2   N/A  N/A     30071      C   python                          15717MiB |\n",
      "|    3   N/A  N/A      5158      C   python                          11593MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/\n"
     ]
    }
   ],
   "source": [
    "print(data_path)"
=======
   "execution_count": 66,
   "id": "06a2c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to2DArray(x): \n",
    "    x=x.replace(\"[\", '')\n",
    "    x=x.replace(\"]\", '')\n",
    "    x=x.replace(\"...\", '')\n",
    "    x=x.replace(\"\\n\", '')\n",
    "    y=np.array(x.split(\" \"))\n",
    "    y = y[y != \"\"]\n",
    "    y = np.asfarray(y, 'float64')\n",
    "    y = np.reshape(y,(1, y.size))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10b12103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spec'] = df['spec'].apply(lambda x: to2DArray(x))"
>>>>>>> origin/j-huzar
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to2DArray(x): \n",
    "    x=x.replace(\"[\", '')\n",
    "    x=x.replace(\"]\", '')\n",
    "    x=x.replace(\"...\", '')\n",
    "    x=x.replace(\"\\n\", '')\n",
    "    y=np.array(x.split(\" \"))\n",
    "    y = y[y != \"\"]\n",
    "    y = np.asfarray(y, 'float64')\n",
    "    y = np.reshape(y,(1, y.size))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'spec'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4e27f7a81c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spec'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mto2DArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'spec'"
     ]
    }
   ],
   "source": [
    "df['mspec_db'] = df['mspec_db'].apply(lambda x: to2DArray(x))\n",
    "df['chroma_db'] = df['chroma_db'].apply(lambda x: to2DArray(x))\n",
    "df['stft_db'] = df['stft_db'].apply(lambda x: to2DArray(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 68,
   "id": "6a79ff8e-646d-4408-a7c5-081beee62e33",
>>>>>>> origin/j-huzar
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFCXDatasetFromArr(td.Dataset):\n",
    "    def __init__(self, df):\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "         # need this to transform data to tensors    \n",
    "        self.transform = transforms.ToTensor()\n",
    "                \n",
    "        labels = df['species_id'].to_list()\n",
    "        for label in labels:\n",
    "            label_arr = np.zeros(24, dtype=np.single)\n",
    "            label_arr[label] = 1.\n",
    "            self.labels.append(label_arr)\n",
    "             \n",
    "        specs = df['spec']\n",
    "            \n",
    "        for i in range(len(specs)):\n",
    "            current_spec = np.array(specs[i])\n",
    "            dwt_decomp = pywt.dwt2(current_spec, 'bior1.3')\n",
    "            LL, (LH, HL, HH) = dwt_decomp\n",
    "            stack = np.stack([LH, HL, HH])\n",
    "            self.data.append((LH, HL, HH))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.data[idx]), torch.tensor(self.labels[idx]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 69,
   "id": "94cbc71b-5011-4a5f-8a10-088b7fc79298",
>>>>>>> origin/j-huzar
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = None\n",
    "val_df = None\n",
    "\n",
    "# df = pd.read_csv(data_path + 'train_spectograms.csv')\n",
    "X = df.drop('species_id', axis=1)\n",
    "y = df['species_id']\n",
    "\n",
    "strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng_seed) #Use All folds on training loop\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(strat.split(X,y)):\n",
    "    if fold==0:\n",
    "        train_df = df.iloc[train_index]\n",
    "        val_df = df.iloc[val_index]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RFCXDatasetFromArr(train_df)\n",
    "val_dataset = RFCXDatasetFromArr(val_df)"
   ]
  },
  {
=======
>>>>>>> origin/j-huzar
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 Research Reference: https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#data-augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading up on ResNet at the above link, SGD was recommended as an optimizer. Went with a recommended learning rate scheduler from a related notebook in Kaggle. The above link recommends a different scheduler. We chose to use BCE w/ Logits Loss also based on recommendations from related work. We plan on trying out multiple different loss functions to see what works best for our problem. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 70,
   "id": "6c456c6e-a476-4bbb-a4ad-a0d227711ddd",
>>>>>>> origin/j-huzar
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
<<<<<<< HEAD
     "execution_count": 16,
=======
     "execution_count": 70,
>>>>>>> origin/j-huzar
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model definition \n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "pos_weight = (torch.ones(num_species) * num_species)\n",
    "\n",
    "# load model into GPU\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight)\n",
    "\n",
    "loss_function.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "44e30d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freqs = pd.DataFrame(df.species_id.value_counts())\n",
    "#num_total = sum(freqs['species_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4039b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freqs['species_id'] = freqs['species_id'].apply(lambda x: x/num_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4116447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24., 24.,\n",
       "        24., 24., 24., 24., 24., 24., 24., 24., 24., 24.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try Weighting posititons based on frequency\n",
    "#torch.ones(num_species) * num_species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see the shape of our model. Note that ResNet50 has an output dimension of 2048, which we pass through a fully connected layer. The output of our fc layer is in agreement with competition standards. We designed the FC layer based on related work, and will optimize it in later phases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop based on the work of another Kaggle notebook: https://www.kaggle.com/fffrrt/all-in-one-rfcx-baseline-for-beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintains a validation accuracy statistic (Does the most probable class match the ground-truth label?) as the model trains, and saves the model with the highest validation accuracy to the project directory."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 71,
   "id": "b35eb353-32f5-4ff2-ade3-f2656c42be5f",
>>>>>>> origin/j-huzar
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function, best_correct, e_poch):\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "    for e in range(0, 20):\n",
=======
    "    for e in range(0, e_poch):\n",
>>>>>>> origin/j-huzar
    "        train_loss = []\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader):\n",
    "\n",
    "#             print(data.shape)\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "#                 print(\"Loading training data to device\")\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output = output.cuda()\n",
    "            \n",
    "            loss = loss_function(output, target)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            lr = g['lr']\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Training Loss: \", str(sum(train_loss) / len(train_loss)))\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_corr = []\n",
    "\n",
    "            model.eval()\n",
    "            for batch, (data, target) in enumerate(val_loader):\n",
    "                data = data.float()\n",
    "                if torch.cuda.is_available():\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "        \n",
    "                \n",
    "                output = model(data)\n",
    "                loss = loss_function(output, target)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                vals, answers = torch.max(output, 1)\n",
    "                vals, targets = torch.max(target, 1)\n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "                val_corr.append(corrects)\n",
    "\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Validation Loss: \", str(sum(val_loss) / len(val_loss)))\n",
    "\n",
    "\n",
    "        if sum(val_corr) > best_correct:\n",
    "            print('Saving new best model at epoch ' + str(e) + ' (' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()) + ')')\n",
    "            torch.save(model, 'best_model.pt')\n",
    "            best_correct = sum(val_corr)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    del model\n",
    "    \n",
    "    return best_correct"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 74,
   "id": "e90d7ad4-0d75-4ba6-baf5-f01790b6955c",
>>>>>>> origin/j-huzar
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
<<<<<<< HEAD
      "Learning Rate:  0.01\n",
      "Training Loss:  4.867156464545453\n",
      "Epoch:  0\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.7197561956221055\n",
      "Saving new best model at epoch 0 (15/244)\n",
      "Epoch:  1\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.205348202439605\n",
      "Epoch:  1\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  7.203796763573924\n",
      "Saving new best model at epoch 1 (22/244)\n",
      "Epoch:  2\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.1474448325204065\n",
      "Epoch:  2\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.956055225864533\n",
      "Epoch:  3\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.171266010550202\n",
      "Epoch:  3\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.309998412286082\n",
      "Epoch:  4\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.156220074559822\n",
      "Epoch:  4\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.706816296423635\n",
      "Epoch:  5\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.111804878125425\n",
      "Epoch:  5\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.221887780774024\n",
      "Epoch:  6\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.060870784227966\n",
      "Epoch:  6\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.161533224967219\n",
      "Epoch:  7\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.006753589286179\n",
      "Epoch:  7\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.115868968348349\n",
      "Epoch:  8\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.003715257175633\n",
      "Epoch:  8\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.151310074713923\n",
      "Epoch:  9\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.006373294064256\n",
      "Epoch:  9\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.167492558879237\n",
      "Epoch:  10\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.003004701411138\n",
      "Epoch:  10\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.287327120381017\n",
      "Epoch:  11\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  3.998606978869829\n",
      "Epoch:  11\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.303676412951562\n",
      "Epoch:  12\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.010025731852798\n",
      "Epoch:  12\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.429811654552337\n",
      "Epoch:  13\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.025019145402752\n",
      "Epoch:  13\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.131029075191867\n",
      "Epoch:  14\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.9796213536966043\n",
      "Epoch:  14\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.137112417528706\n",
      "Epoch:  15\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.9650647366633183\n",
      "Epoch:  15\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.218139463855374\n",
      "Epoch:  16\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.970860258477633\n",
      "Epoch:  16\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.106593785747405\n",
      "Epoch:  17\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.9588174077331044\n",
      "Epoch:  17\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.130562274686752\n",
      "Epoch:  18\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.96068130360275\n",
      "Epoch:  18\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.142181165756718\n",
      "Epoch:  19\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.957996231610658\n",
      "Epoch:  19\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.133780141030589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
=======
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.9744152182438333\n",
      "Epoch:  0\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.164167258047288\n",
      "Saving new best model at epoch 0 (20/243)\n",
      "Epoch:  1\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.969722818155758\n",
      "Epoch:  1\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.1145499598595405\n",
      "Epoch:  2\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.9875966584096187\n",
      "Epoch:  2\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.100932959587343\n",
      "Epoch:  3\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.9738527301882134\n",
      "Epoch:  3\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.146134215016519\n",
      "Epoch:  4\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.962523524878455\n",
      "Epoch:  4\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.175304320550734\n",
      "Epoch:  0\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.9836811296275405\n",
      "Epoch:  0\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.12829803651379\n",
      "Epoch:  1\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.98420563877606\n",
      "Epoch:  1\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.081763605917653\n",
      "Epoch:  2\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.974024116015825\n",
      "Epoch:  2\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.1065602840915805\n",
      "Epoch:  3\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.9714651674520773\n",
      "Epoch:  3\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.07711596642771\n",
      "Epoch:  4\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.9622236783387232\n",
      "Epoch:  4\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.083129021429246\n",
      "Epoch:  5\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.948016536040384\n",
      "Epoch:  5\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.092950682486257\n",
      "Epoch:  6\n",
      "Learning Rate:  0.0001\n",
      "Training Loss:  3.9767342649522375\n",
      "Epoch:  6\n",
      "Learning Rate:  0.0001\n",
      "Validation Loss:  4.153736575957267\n",
      "Epoch:  7\n",
      "Learning Rate:  4e-05\n",
      "Training Loss:  3.9700371105162824\n",
      "Epoch:  7\n",
      "Learning Rate:  4e-05\n",
      "Validation Loss:  4.079306763987387\n",
      "Epoch:  8\n",
      "Learning Rate:  4e-05\n",
      "Training Loss:  3.97024459330762\n",
      "Epoch:  8\n",
      "Learning Rate:  4e-05\n",
      "Validation Loss:  4.082791966776694\n",
      "Epoch:  9\n",
      "Learning Rate:  4e-05\n",
      "Training Loss:  3.9721385553234914\n",
      "Epoch:  9\n",
      "Learning Rate:  4e-05\n",
      "Validation Loss:  4.087958681967951\n",
      "Epoch:  0\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9762929345740647\n",
      "Epoch:  0\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.1417139960873515\n",
      "Epoch:  1\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.970536814361322\n",
      "Epoch:  1\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.165508985519409\n",
      "Epoch:  2\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.979870581236042\n",
      "Epoch:  2\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.180038136820639\n",
      "Epoch:  3\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9727554927106765\n",
      "Epoch:  3\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.145096640433034\n",
      "Epoch:  4\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9829954631993028\n",
      "Epoch:  4\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.075243226943478\n",
      "Epoch:  0\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9576707863416827\n",
      "Epoch:  0\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.084080096214048\n",
      "Epoch:  1\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9773350895428266\n",
      "Epoch:  1\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.056003547483875\n",
      "Epoch:  2\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9603977457421724\n",
      "Epoch:  2\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.065191615012385\n",
      "Epoch:  3\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9859110351468696\n",
      "Epoch:  3\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.02580730376705\n",
      "Saving new best model at epoch 3 (27/243)\n",
      "Epoch:  4\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.962761890692789\n",
      "Epoch:  4\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.08581676021699\n",
      "Epoch:  5\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.96085946481736\n",
      "Epoch:  5\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.045139774199455\n",
      "Epoch:  6\n",
      "Learning Rate:  0.001\n",
      "Training Loss:  3.9619239470997796\n",
      "Epoch:  6\n",
      "Learning Rate:  0.001\n",
      "Validation Loss:  4.053243798594321\n",
      "Epoch:  7\n",
      "Learning Rate:  0.0004\n",
      "Training Loss:  3.9655878133461124\n",
      "Epoch:  7\n",
      "Learning Rate:  0.0004\n",
      "Validation Loss:  4.037688962874874\n",
      "Epoch:  8\n",
      "Learning Rate:  0.0004\n",
      "Training Loss:  3.963685188137117\n",
      "Epoch:  8\n",
      "Learning Rate:  0.0004\n",
      "Validation Loss:  4.029656756308771\n",
      "Epoch:  9\n",
      "Learning Rate:  0.0004\n",
      "Training Loss:  3.9494934551051406\n",
      "Epoch:  9\n",
      "Learning Rate:  0.0004\n",
      "Validation Loss:  4.038874556941371\n",
      "Best Learning Rate is 0.001\n",
      "Best Epochs is 10\n"
     ]
>>>>>>> origin/j-huzar
    }
   ],
   "source": [
    "best_correct = 0\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = td.RandomSampler(train_dataset))\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = td.RandomSampler(val_dataset))\n",
    "lr_vals = [.0001,.001, .01, .1]\n",
    "epochs = [20,25,35,50]\n",
    "pos_weight = []\n",
    "for x in range(len(lr_vals)):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_vals[x], weight_decay=0.0001, momentum=0.9)\n",
    "    for y in range(len(epochs)):\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4)\n",
    "        best_correct_new = training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function, best_correct, epochs[y])\n",
    "        if(best_correct_new > best_correct):\n",
    "            best_correct = best_correct_new\n",
    "            best_epoch = epochs[y]\n",
    "            best_lr = lr_vals[x]\n",
    "print(\"Best Learning Rate is {}\".format(best_lr))\n",
    "print(\"Best Epochs is {}\".format(best_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc5410",
   "metadata": {},
   "source": [
    "### Submission Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b00554",
   "metadata": {},
   "source": [
    "Based on the work of another Kaggle notebook: https://www.kaggle.com/fffrrt/all-in-one-rfcx-baseline-for-beginners. (Should edit before final project done)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tuk99233/rainforest-audio-detection/Code'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
=======
   "execution_count": 33,
   "id": "5e12cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mel_spectograms(df):\n",
    "    wav, sr = librosa.load(\"test/{}\".format(df), sr=None)\n",
    "\n",
    "    # Split for enough segments to not miss anything\n",
    "    segments = len(wav) / length\n",
    "    segments = int(np.ceil(segments))\n",
    "    \n",
    "    mel_array = []\n",
    "    \n",
    "    for i in range(0, segments):\n",
    "        # Last segment going from the end\n",
    "        if (i + 1) * length > len(wav):\n",
    "            slice = wav[len(wav) - length:len(wav)]\n",
    "        else:\n",
    "            slice = wav[i * length:(i + 1) * length]\n",
    "        \n",
    "        # Same mel spectrogram as before\n",
    "        mel_spec = librosa.feature.melspectrogram(slice, n_fft=fft, hop_length=hop, sr=sr)\n",
    "        mel_spec = resize(mel_spec, mel_spec_dimensions)\n",
    "    \n",
    "        mel_spec = mel_spec - np.min(mel_spec)\n",
    "        mel_spec = mel_spec / np.max(mel_spec)\n",
    "        \n",
    "        mel_spec = np.stack((mel_spec, mel_spec, mel_spec))\n",
    "\n",
    "        mel_array.append(mel_spec)\n",
    "    \n",
    "    return mel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ad249f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction loop\n",
      "1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15750/702873193.py:36: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:207.)\n",
      "  data = torch.tensor(data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted for 100 of 1993 files\n",
      "Predicted for 200 of 1993 files\n",
      "Predicted for 300 of 1993 files\n",
      "Predicted for 400 of 1993 files\n",
      "Predicted for 500 of 1993 files\n",
      "Predicted for 600 of 1993 files\n",
      "Predicted for 700 of 1993 files\n",
      "Predicted for 800 of 1993 files\n",
      "Predicted for 900 of 1993 files\n",
      "Predicted for 1000 of 1993 files\n",
      "Predicted for 1100 of 1993 files\n",
      "Predicted for 1200 of 1993 files\n",
      "Predicted for 1300 of 1993 files\n",
      "Predicted for 1400 of 1993 files\n",
      "Predicted for 1500 of 1993 files\n",
      "Predicted for 1600 of 1993 files\n",
      "Predicted for 1700 of 1993 files\n",
      "Predicted for 1800 of 1993 files\n",
      "Predicted for 1900 of 1993 files\n",
      "Submission generated\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "model = torch.load('best_model.pt')\n",
    "model.eval()\n",
    "\n",
    "# Scoring does not like many files:(\n",
    "#if save_to_disk == 0:\n",
    "#    for f in os.listdir('/kaggle/working/'):\n",
    "#        os.remove('/kaggle/working/' + f)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Prediction loop\n",
    "print('Starting prediction loop')\n",
    "with open('submission.csv', 'w', newline='') as csvfile:\n",
    "    submission_writer = csv.writer(csvfile, delimiter=',')\n",
    "    submission_writer.writerow(['recording_id','s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10','s11',\n",
    "                               's12','s13','s14','s15','s16','s17','s18','s19','s20','s21','s22','s23'])\n",
    "    \n",
    "    test_files = os.listdir('../test/') \n",
    "    print(len(test_files))\n",
    "    \n",
    "    # Every test file is split on several chunks and prediction is made for each chunk\n",
    "    for i in range(0, len(test_files)):\n",
    "        data = create_mel_spectograms(test_files[i])\n",
    "        data = torch.tensor(data)\n",
    "        data = data.float()\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        # Taking max prediction from all slices per bird species\n",
    "        # Usually you want Sigmoid layer here to convert output to probabilities\n",
    "        # In this competition only relative ranking matters, and not the exact value of prediction, so we can use it directly\n",
    "        maxed_output = torch.max(output, dim=0)[0]\n",
    "        maxed_output = maxed_output.cpu().detach()\n",
    "        \n",
    "        file_id = str.split(test_files[i], '.')[0]\n",
    "        write_array = [file_id]\n",
    "        \n",
    "        for out in maxed_output:\n",
    "            write_array.append(out.item())\n",
    "    \n",
    "        submission_writer.writerow(write_array)\n",
    "        \n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print('Predicted for ' + str(i) + ' of ' + str(len(test_files) + 1) + ' files')\n",
    "\n",
    "print('Submission generated')"
>>>>>>> origin/j-huzar
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
