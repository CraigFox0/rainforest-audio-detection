{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba842dda-e473-4329-aa3b-e819bd1e05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import soundfile as sf \n",
    "import librosa\n",
    "from skimage.transform import resize \n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader \n",
    "import torch.utils.data as td\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.utils.data as td \n",
    "# Setting seeds for reproducible results \n",
    "rng_seed = 1234\n",
    "random.seed(rng_seed)\n",
    "np.random.seed(rng_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(rng_seed)\n",
    "torch.manual_seed(rng_seed)\n",
    "torch.cuda.manual_seed(rng_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "num_species = 24\n",
    "batch_size = 8\n",
    "\n",
    "fft = 2048\n",
    "hop = 512 \n",
    "# According to research, standard sampling bitrate is 48khz. Seen in discussion of kaggle competition as well. \n",
    "sr = 48000\n",
    "length = 10*sr\n",
    "# ResNet50 input layer is 224 x 224 x 3, so I'm resizing the image to fit the first input dimension. \n",
    "mel_spec_dimensions = (224,224)\n",
    "\n",
    "data_path = '../Data/'\n",
    "\n",
    "#df = pd.read_csv(data_path + 'train_tp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42dc27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9e988",
   "metadata": {},
   "source": [
    "### Cuda Device Selection\n",
    "\n",
    "Use cuda:{device_num} to select cuda device that is not being used already\n",
    "\n",
    "Make sure that this device is selected by exporting CUDA_VISIBLE_DEVICES={device_num} on the shell that's running the notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e449b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 10 16:17:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.39.01    Driver Version: 510.39.01    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   52C    P0   291W / 300W |  10042MiB / 16384MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   60C    P0   285W / 300W |  11206MiB / 16384MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:84:00.0 Off |                    0 |\n",
      "| N/A   57C    P0   279W / 300W |  15720MiB / 16384MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    63W / 300W |  11598MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     27637      C   python                          10039MiB |\n",
      "|    1   N/A  N/A     24201      C   python                          11201MiB |\n",
      "|    2   N/A  N/A     30071      C   python                          15717MiB |\n",
      "|    3   N/A  N/A      5158      C   python                          11593MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4d85c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99228445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/\n"
     ]
    }
   ],
   "source": [
    "print(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698e38d5-436f-4a9d-bdb0-4f16058010a9",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790ae1c-8353-4566-9d52-f482a341ca8d",
   "metadata": {},
   "source": [
    "Just using a quick technique for now, worried only about getting model results back. Will use different preprocessing steps as we move on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5735bff2-4e1c-4699-b638-683f152f6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mel_spectograms(df):\n",
    "#     df['spec'] = np.nan\n",
    "#     df['spec'] = df['spec'].astype(object)\n",
    "    \n",
    "#     for idx,row in df.iterrows():\n",
    "        \n",
    "#         rid = row['recording_id']\n",
    "\n",
    "#         wav, sr = librosa.load(data_path + 'train/' + rid + '.flac', sr=None)\n",
    "\n",
    "#         # Slicing and centering spectograms \n",
    "#         m = np.round((row['t_min'] + row['t_max']) / 2)\n",
    "#         l = m - length / 2\n",
    "#         if l < 0: l = 0\n",
    "#         r = m + length\n",
    "#         if r > len(wav):\n",
    "#             r = len(wav)\n",
    "#             l = r - m\n",
    "\n",
    "#         mspec = librosa.feature.melspectrogram(y=wav[int(l):int(r)], n_fft=fft, hop_length=hop, sr=sr)\n",
    "#         mspec = resize(mspec, mel_spec_dimensions)\n",
    "#         mspec = (mspec - np.min(mspec))/np.max(mspec)\n",
    "            \n",
    "#         df.at[idx, 'spec'] = mspec\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e6d49",
   "metadata": {},
   "source": [
    "### Optional: Rerun Mel Spectogram Pipeline \n",
    "\n",
    "Note: should not be necessary if up to date with main branch\n",
    "train_spectograms.csv should already be saved at Data/train_spectograms.csv, though we might need to pickle the spec 2d array so that we can retrieve it for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6d563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21cc00a-ad40-4342-815f-9282d66b6f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = create_mel_spectograms(df)\n",
    "# df.to_csv(data_path + 'train_spectograms.csv')\n",
    "# print(df.dtypes)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bbd556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/train_spectograms.csv') #File Containing the Spectograms as String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e877b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>recording_id</th>\n",
       "      <th>species_id</th>\n",
       "      <th>songtype_id</th>\n",
       "      <th>t_min</th>\n",
       "      <th>f_min</th>\n",
       "      <th>t_max</th>\n",
       "      <th>f_max</th>\n",
       "      <th>spec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>003bec244</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.5440</td>\n",
       "      <td>2531.250</td>\n",
       "      <td>45.1307</td>\n",
       "      <td>5531.25</td>\n",
       "      <td>[[1.5969152e-02 6.8952353e-03 4.4541932e-03 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>006ab765f</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39.9615</td>\n",
       "      <td>7235.160</td>\n",
       "      <td>46.0452</td>\n",
       "      <td>11283.40</td>\n",
       "      <td>[[9.6064601e-03 2.7989434e-02 6.6220999e-02 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>007f87ba2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>39.1360</td>\n",
       "      <td>562.500</td>\n",
       "      <td>42.2720</td>\n",
       "      <td>3281.25</td>\n",
       "      <td>[[9.5930777e-02 2.4144638e-01 7.8364432e-02 .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0099c367b</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>51.4206</td>\n",
       "      <td>1464.260</td>\n",
       "      <td>55.1996</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>[[0.10142235 0.08636865 0.07434975 ... 0.16675...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>009b760e6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>50.0854</td>\n",
       "      <td>947.461</td>\n",
       "      <td>52.5293</td>\n",
       "      <td>10852.70</td>\n",
       "      <td>[[1.25540704e-01 3.26309167e-02 1.82776209e-02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 recording_id  species_id  songtype_id    t_min     f_min  \\\n",
       "0           0    003bec244          14            1  44.5440  2531.250   \n",
       "1           1    006ab765f          23            1  39.9615  7235.160   \n",
       "2           2    007f87ba2          12            1  39.1360   562.500   \n",
       "3           3    0099c367b          17            4  51.4206  1464.260   \n",
       "4           4    009b760e6          10            1  50.0854   947.461   \n",
       "\n",
       "     t_max     f_max                                               spec  \n",
       "0  45.1307   5531.25  [[1.5969152e-02 6.8952353e-03 4.4541932e-03 .....  \n",
       "1  46.0452  11283.40  [[9.6064601e-03 2.7989434e-02 6.6220999e-02 .....  \n",
       "2  42.2720   3281.25  [[9.5930777e-02 2.4144638e-01 7.8364432e-02 .....  \n",
       "3  55.1996   4565.04  [[0.10142235 0.08636865 0.07434975 ... 0.16675...  \n",
       "4  52.5293  10852.70  [[1.25540704e-01 3.26309167e-02 1.82776209e-02...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06a2c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to2DArray(x): \n",
    "    x=x.replace(\"[\", '')\n",
    "    x=x.replace(\"]\", '')\n",
    "    x=x.replace(\"...\", '')\n",
    "    x=x.replace(\"\\n\", '')\n",
    "    y=np.array(x.split(\" \"))\n",
    "    y = y[y != \"\"]\n",
    "    y = np.asfarray(y, 'float64')\n",
    "    y = np.reshape(y,(1, y.size))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b12103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spec'] = df['spec'].apply(lambda x: to2DArray(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fedf57-304f-41c8-96fd-52e48e42a7b1",
   "metadata": {},
   "source": [
    "### Creating PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dee5c6-600e-4653-9d98-9e8fc2569f35",
   "metadata": {},
   "source": [
    "Note: Have to stack the spectrograms so that they're (224 x 224 x 3) to fit the input dimensions of ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a79ff8e-646d-4408-a7c5-081beee62e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFCXDatasetFromArr(td.Dataset):\n",
    "    def __init__(self, df):\n",
    "        \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "         # need this to transform data to tensors    \n",
    "        self.transform = transforms.ToTensor()\n",
    "                \n",
    "        labels = df['species_id'].to_list()\n",
    "        for label in labels:\n",
    "            label_arr = np.zeros(24, dtype=np.single)\n",
    "            label_arr[label] = 1.\n",
    "            self.labels.append(label_arr)\n",
    "             \n",
    "        specs = df['spec']\n",
    "            \n",
    "        for i in range(len(specs)):\n",
    "            current_spec = np.array(specs[i])\n",
    "            stack = np.stack([current_spec, current_spec, current_spec])\n",
    "            self.data.append(stack)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.data[idx]), torch.tensor(self.labels[idx]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ef2b9-8a3a-4c54-bfaa-1d2da6a37837",
   "metadata": {},
   "source": [
    "### Creating Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94cbc71b-5011-4a5f-8a10-088b7fc79298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = None\n",
    "val_df = None\n",
    "\n",
    "# df = pd.read_csv(data_path + 'train_spectograms.csv')\n",
    "X = df.drop('species_id', axis=1)\n",
    "y = df['species_id']\n",
    "\n",
    "strat = StratifiedKFold(n_splits=5, shuffle=True, random_state=rng_seed)\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(strat.split(X,y)):\n",
    "    if fold==0:\n",
    "        train_df = df.iloc[train_index]\n",
    "        val_df = df.iloc[val_index]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff776c47-726b-4e40-ad2f-3f77f529aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RFCXDatasetFromArr(train_df)\n",
    "val_dataset = RFCXDatasetFromArr(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5705cf8a-8b5f-4012-98f6-195c702627d5",
   "metadata": {},
   "source": [
    "### Configuring Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757fbdb6-cd40-4377-ac64-7e595960ecd5",
   "metadata": {},
   "source": [
    "ResNet50 Research Reference: https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5#data-augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d8d59-d5e4-44f8-b34c-e0478d9fe546",
   "metadata": {},
   "source": [
    "After reading up on ResNet at the above link, SGD was recommended as an optimizer. Went with a recommended learning rate scheduler from a related notebook in Kaggle. The above link recommends a different scheduler. We chose to use BCE w/ Logits Loss also based on recommendations from related work. We plan on trying out multiple different loss functions to see what works best for our problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c456c6e-a476-4bbb-a4ad-a0d227711ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, sampler = td.RandomSampler(train_dataset))\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, sampler = td.RandomSampler(val_dataset))\n",
    "\n",
    "# Model definition \n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, num_species)\n",
    ")\n",
    "\n",
    "pos_weight = (torch.ones(num_species) * num_species)\n",
    "\n",
    "# load model into GPU\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.0001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.4)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight)\n",
    "\n",
    "loss_function.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e913cff-9d7a-4e70-8354-4f852a091d28",
   "metadata": {},
   "source": [
    "Below, we can see the shape of our model. Note that ResNet50 has an output dimension of 2048, which we pass through a fully connected layer. The output of our fc layer is in agreement with competition standards. We designed the FC layer based on related work, and will optimize it in later phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133f0efa-98bc-4d2e-ab83-f99dc400c77e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54d7b8-6d82-4594-bf6a-670e0041cd15",
   "metadata": {},
   "source": [
    "Training loop based on the work of another Kaggle notebook: https://www.kaggle.com/fffrrt/all-in-one-rfcx-baseline-for-beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833d7b5-c255-435b-bb45-683ee6032514",
   "metadata": {},
   "source": [
    "Maintains a validation accuracy statistic (Does the most probable class match the ground-truth label?) as the model trains, and saves the model with the highest validation accuracy to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b35eb353-32f5-4ff2-ade3-f2656c42be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function):\n",
    "    best_corrects = 0\n",
    "\n",
    "\n",
    "    for e in range(0, 20):\n",
    "        train_loss = []\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for batch, (data, target) in enumerate(train_loader):\n",
    "\n",
    "#             print(data.shape)\n",
    "            data = data.float()\n",
    "            if torch.cuda.is_available():\n",
    "#                 print(\"Loading training data to device\")\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output = output.cuda()\n",
    "            \n",
    "            loss = loss_function(output, target)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            lr = g['lr']\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Training Loss: \", str(sum(train_loss) / len(train_loss)))\n",
    "\n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            val_loss = []\n",
    "            val_corr = []\n",
    "\n",
    "            model.eval()\n",
    "            for batch, (data, target) in enumerate(val_loader):\n",
    "                data = data.float()\n",
    "                if torch.cuda.is_available():\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "        \n",
    "                \n",
    "                output = model(data)\n",
    "                loss = loss_function(output, target)\n",
    "\n",
    "                val_loss.append(loss.item())\n",
    "\n",
    "                vals, answers = torch.max(output, 1)\n",
    "                vals, targets = torch.max(target, 1)\n",
    "                corrects = 0\n",
    "                for i in range(0, len(answers)):\n",
    "                    if answers[i] == targets[i]:\n",
    "                        corrects = corrects + 1\n",
    "                val_corr.append(corrects)\n",
    "\n",
    "\n",
    "        print(\"Epoch: \", str(e))\n",
    "        print(\"Learning Rate: \", str(lr))\n",
    "        print(\"Validation Loss: \", str(sum(val_loss) / len(val_loss)))\n",
    "\n",
    "\n",
    "        if sum(val_corr) > best_corrects:\n",
    "            print('Saving new best model at epoch ' + str(e) + ' (' + str(sum(val_corr)) + '/' + str(val_dataset.__len__()) + ')')\n",
    "            torch.save(model, 'best_model.pt')\n",
    "            best_corrects = sum(val_corr)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    del model\n",
    "    \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e90d7ad4-0d75-4ba6-baf5-f01790b6955c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.867156464545453\n",
      "Epoch:  0\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.7197561956221055\n",
      "Saving new best model at epoch 0 (15/244)\n",
      "Epoch:  1\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.205348202439605\n",
      "Epoch:  1\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  7.203796763573924\n",
      "Saving new best model at epoch 1 (22/244)\n",
      "Epoch:  2\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.1474448325204065\n",
      "Epoch:  2\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.956055225864533\n",
      "Epoch:  3\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.171266010550202\n",
      "Epoch:  3\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.309998412286082\n",
      "Epoch:  4\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.156220074559822\n",
      "Epoch:  4\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.706816296423635\n",
      "Epoch:  5\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.111804878125425\n",
      "Epoch:  5\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.221887780774024\n",
      "Epoch:  6\n",
      "Learning Rate:  0.01\n",
      "Training Loss:  4.060870784227966\n",
      "Epoch:  6\n",
      "Learning Rate:  0.01\n",
      "Validation Loss:  4.161533224967219\n",
      "Epoch:  7\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.006753589286179\n",
      "Epoch:  7\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.115868968348349\n",
      "Epoch:  8\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.003715257175633\n",
      "Epoch:  8\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.151310074713923\n",
      "Epoch:  9\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.006373294064256\n",
      "Epoch:  9\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.167492558879237\n",
      "Epoch:  10\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.003004701411138\n",
      "Epoch:  10\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.287327120381017\n",
      "Epoch:  11\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  3.998606978869829\n",
      "Epoch:  11\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.303676412951562\n",
      "Epoch:  12\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.010025731852798\n",
      "Epoch:  12\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.429811654552337\n",
      "Epoch:  13\n",
      "Learning Rate:  0.004\n",
      "Training Loss:  4.025019145402752\n",
      "Epoch:  13\n",
      "Learning Rate:  0.004\n",
      "Validation Loss:  4.131029075191867\n",
      "Epoch:  14\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.9796213536966043\n",
      "Epoch:  14\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.137112417528706\n",
      "Epoch:  15\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.9650647366633183\n",
      "Epoch:  15\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.218139463855374\n",
      "Epoch:  16\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.970860258477633\n",
      "Epoch:  16\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.106593785747405\n",
      "Epoch:  17\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.9588174077331044\n",
      "Epoch:  17\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.130562274686752\n",
      "Epoch:  18\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.96068130360275\n",
      "Epoch:  18\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.142181165756718\n",
      "Epoch:  19\n",
      "Learning Rate:  0.0016\n",
      "Training Loss:  3.957996231610658\n",
      "Epoch:  19\n",
      "Learning Rate:  0.0016\n",
      "Validation Loss:  4.133780141030589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(train_loader, val_loader, model, optimizer, scheduler, pos_weight, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65fa42ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tuk99233/rainforest-audio-detection/Code'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
